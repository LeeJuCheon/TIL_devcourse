# Day 1 Autonomous Driving introduction

1. 자율주행 개념
* 자율주행의 정의 : 운전자의 개입 없이 목적지까지 차량 스스로 움직이는 기술
* Perception : 자율주행 차량의 주행환경에 대한 다양한 정보를 인지하는 기술
* Localization : 자율주행 차량의 현재 위치를 추정하는 기술
  * GPS / SLAM,INS&IMU Fusion, Map Matching
* Planning : 자율주행 차량의 주행 환경, 위치 정보를 바탕으로 주행하는데 필요한 요소(경로,판단 등)를 생성 및 결정하는 기술(gpp(global path planing) ,lpp(local path planing), mission planing, decisison making)
  * GPP : 내비게이션과 같은 현재 위치로부터 목적지까지의 도로 단위를 결정
  * LPP : 현재 주행환경에서 원활한 주행을 위한 차선 단위의 경로를 결정
* Control : 자율주행 차량이 원활한 주행을 할 수 있도록 차량을 제어하는 기술

2. 자율주행의 두가지 갈래
* 정밀지도 기반 자율주행(LiDAR 기반) - [WAYMO]
* 비 정밀지도 기반 자율주행(Vision 기반) - [mobileye, TESLA]
  * Harvesting - Alignment - Modeling & Semantics

3. Perception
* 기술
  * Detection
    * Vision, LiDAR, RADAR등 다양한 센서를 활용하여 객체를 탐지
    * Vision 기반 2D Image Object Detection
    * LiDAR 또는 RADAR를 활용한 3D Point Cloud Object Detection
  * Segmentation
    * 객체의 형태를 분할하는 기법
    * Instance Segmentation, sementic segmentation
    * 도로를 인식하는 Drivable Area Detection이 대표적인 활용사례
  * Tracking
    * 검출한 객체의 고유한 ID 부여, 추적기능
  * Prediction
    * 객체의 현재까지의 움직임과 객체의 고유한 특징 등 다양한 정보를 바탕으로 미래 움직임을 추정
    * Multimodal Trajectory Prediction
  * 3D POSE Estimation
    * 객체의 정확한 위치 추정
    * Geometry 정보 사용 or 다른센서와의 융합
    * Multiple view geometry 분야의 기술 활용

  * Sensor Fusion
    * Camera VS LiDAR
        * 라이다는 객체를 구분할 수 없지만 위치 정보 획득 가능
        * 카메라는 객체의 위치 정보를 획득할 수 없지만 대상이 무엇인지 구별 가능
    * 센서를 융합하는 기법(Calibration)
  * Acceleration
    * 여러 알고리즘들이 DL 기반으로 변화하면서 컴퓨팅 파워에 대한 수요가 급증
    * Model Quantization
      * 모델 양자화
    * Pruning(가지치기)
    * Hardware Optimization

4. 이후 수업 
* 인식해야 하는 대상에 대한 데이터 준비
* 환경 또는 대상이 변화하는 경우?